{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52c33eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>social_timestamp</th>\n",
       "      <th>social_karma</th>\n",
       "      <th>syntax_ari</th>\n",
       "      <th>lex_liwc_WC</th>\n",
       "      <th>lex_liwc_Analytic</th>\n",
       "      <th>lex_liwc_Clout</th>\n",
       "      <th>lex_liwc_Authentic</th>\n",
       "      <th>lex_liwc_Tone</th>\n",
       "      <th>...</th>\n",
       "      <th>Tokenized_Segment_1601</th>\n",
       "      <th>Tokenized_Segment_1602</th>\n",
       "      <th>Tokenized_Segment_1603</th>\n",
       "      <th>Tokenized_Segment_1604</th>\n",
       "      <th>Tokenized_Segment_1605</th>\n",
       "      <th>Tokenized_Segment_1606</th>\n",
       "      <th>Tokenized_Segment_1607</th>\n",
       "      <th>Tokenized_Segment_1608</th>\n",
       "      <th>Tokenized_Segment_1609</th>\n",
       "      <th>Tokenized_Segment_1610</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33181</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1521614353</td>\n",
       "      <td>5</td>\n",
       "      <td>1.806818</td>\n",
       "      <td>116</td>\n",
       "      <td>72.64</td>\n",
       "      <td>15.04</td>\n",
       "      <td>89.26</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1527009817</td>\n",
       "      <td>4</td>\n",
       "      <td>9.429737</td>\n",
       "      <td>109</td>\n",
       "      <td>79.08</td>\n",
       "      <td>76.85</td>\n",
       "      <td>56.75</td>\n",
       "      <td>98.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38816</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1535935605</td>\n",
       "      <td>2</td>\n",
       "      <td>7.769821</td>\n",
       "      <td>167</td>\n",
       "      <td>33.80</td>\n",
       "      <td>76.38</td>\n",
       "      <td>86.24</td>\n",
       "      <td>25.77</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1516429555</td>\n",
       "      <td>0</td>\n",
       "      <td>2.667798</td>\n",
       "      <td>273</td>\n",
       "      <td>2.98</td>\n",
       "      <td>15.25</td>\n",
       "      <td>95.42</td>\n",
       "      <td>79.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1539809005</td>\n",
       "      <td>24</td>\n",
       "      <td>7.554238</td>\n",
       "      <td>89</td>\n",
       "      <td>32.22</td>\n",
       "      <td>28.71</td>\n",
       "      <td>84.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4953 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  confidence  social_timestamp  social_karma  syntax_ari  \\\n",
       "id                                                                     \n",
       "33181      1         0.8        1521614353             5    1.806818   \n",
       "2606       0         1.0        1527009817             4    9.429737   \n",
       "38816      1         0.8        1535935605             2    7.769821   \n",
       "239        1         0.6        1516429555             0    2.667798   \n",
       "1421       1         0.8        1539809005            24    7.554238   \n",
       "\n",
       "       lex_liwc_WC  lex_liwc_Analytic  lex_liwc_Clout  lex_liwc_Authentic  \\\n",
       "id                                                                          \n",
       "33181          116              72.64           15.04               89.26   \n",
       "2606           109              79.08           76.85               56.75   \n",
       "38816          167              33.80           76.38               86.24   \n",
       "239            273               2.98           15.25               95.42   \n",
       "1421            89              32.22           28.71               84.01   \n",
       "\n",
       "       lex_liwc_Tone  ...  Tokenized_Segment_1601  Tokenized_Segment_1602  \\\n",
       "id                    ...                                                   \n",
       "33181           1.00  ...                       0                       0   \n",
       "2606           98.18  ...                       0                       0   \n",
       "38816          25.77  ...                       0                       0   \n",
       "239            79.26  ...                       0                       0   \n",
       "1421            1.00  ...                       0                       0   \n",
       "\n",
       "       Tokenized_Segment_1603  Tokenized_Segment_1604  Tokenized_Segment_1605  \\\n",
       "id                                                                              \n",
       "33181                       0                       0                       0   \n",
       "2606                        0                       0                       0   \n",
       "38816                       0                       0                       0   \n",
       "239                         0                       0                       0   \n",
       "1421                        0                       0                       0   \n",
       "\n",
       "       Tokenized_Segment_1606  Tokenized_Segment_1607  Tokenized_Segment_1608  \\\n",
       "id                                                                              \n",
       "33181                       0                       0                       0   \n",
       "2606                        0                       0                       0   \n",
       "38816                       0                       0                       0   \n",
       "239                         0                       0                       0   \n",
       "1421                        0                       0                       0   \n",
       "\n",
       "       Tokenized_Segment_1609  Tokenized_Segment_1610  \n",
       "id                                                     \n",
       "33181                       0                       0  \n",
       "2606                        0                       0  \n",
       "38816                       0                       0  \n",
       "239                         0                       0  \n",
       "1421                        0                       0  \n",
       "\n",
       "[5 rows x 4953 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"./pre_processed_train.csv\",index_col=\"id\")\n",
    "test = pd.read_csv(\"./pre_processed_test.csv\",index_col=\"id\")\n",
    "\n",
    "X=train.copy()\n",
    "X_test=test.copy()\n",
    "\n",
    "\n",
    "y=X.label\n",
    "y_test=X_test.label\n",
    "\n",
    "X=X.drop(['label'],axis=1)\n",
    "X_test=X_test.drop(['label'],axis=1)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0a5fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7db2a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a given model using cross-validation\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "def evaluate_model(model, X, y):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                                train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_hat = model.predict(X_valid)\n",
    "    \n",
    "    return f1_score(y_valid,y_hat,average=\"binary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ea424a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-29 14:55:53,818]\u001b[0m A new study created in memory with name: no-name-8099f10d-57b5-43fb-a317-7fd88b2155ce\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:55:54] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8027/744896019.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8027/744896019.py\u001b[0m in \u001b[0;36mxgb_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     25\u001b[0m                          \u001b[0mtree_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gpu_hist'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                          gpu_id=0)  \n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8027/2711164558.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                                 \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                                 random_state=42)\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m             \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m         )\n\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    195\u001b[0m                           \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                           \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                           early_stopping_rounds=early_stopping_rounds)\n\u001b[0m\u001b[1;32m    198\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Optimizing parameters for XGBoost, GBM, LGBM which gave them highest base accuracy of 78%\n",
    "\n",
    "##XGBoost\n",
    "\n",
    "# optuna to optimize\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def xgb_objective(trial):\n",
    "    \n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 300, 5000)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-1, log=True)\n",
    "    min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 7, step=2)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0, step=0.1)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0, step=0.1)\n",
    "    \n",
    "    model = XGBClassifier(n_estimators=n_estimators,\n",
    "                         max_depth=max_depth,\n",
    "                         learning_rate=learning_rate,\n",
    "                         min_child_weight=min_child_weight,\n",
    "                         colsample_bytree=colsample_bytree,\n",
    "                         subsample=subsample,\n",
    "                         n_jobs=-1, \n",
    "                         tree_method='gpu_hist', \n",
    "                         gpu_id=0)  \n",
    "    return evaluate_model(model, X, y)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(xgb_objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_trial)\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a4faa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-29 14:59:34,674]\u001b[0m A new study created in memory with name: gbm_optimze\u001b[0m\n",
      "\u001b[32m[I 2021-08-29 15:00:06,242]\u001b[0m Trial 0 finished with value: 0.6987399770904925 and parameters: {'n_estimators': 699, 'max_depth': 9, 'learning_rate': 3.682545210834743e-05, 'subsample': 0.7, 'min_samples_split': 750}. Best is trial 0 with value: 0.6987399770904925.\u001b[0m\n",
      "\u001b[32m[I 2021-08-29 15:01:58,923]\u001b[0m Trial 1 finished with value: 0.7625201938610664 and parameters: {'n_estimators': 822, 'max_depth': 8, 'learning_rate': 0.0027409760166850036, 'subsample': 0.8, 'min_samples_split': 100}. Best is trial 1 with value: 0.7625201938610664.\u001b[0m\n",
      "\u001b[32m[I 2021-08-29 15:04:11,669]\u001b[0m Trial 2 finished with value: 0.7445255474452555 and parameters: {'n_estimators': 3777, 'max_depth': 7, 'learning_rate': 4.493602276424878e-05, 'subsample': 0.5, 'min_samples_split': 510}. Best is trial 1 with value: 0.7625201938610664.\u001b[0m\n",
      "\u001b[32m[I 2021-08-29 15:04:43,346]\u001b[0m Trial 3 finished with value: 0.6987399770904925 and parameters: {'n_estimators': 480, 'max_depth': 4, 'learning_rate': 6.614396862987209e-05, 'subsample': 0.9, 'min_samples_split': 680}. Best is trial 1 with value: 0.7625201938610664.\u001b[0m\n",
      "\u001b[32m[I 2021-08-29 15:05:24,371]\u001b[0m Trial 4 finished with value: 0.6987399770904925 and parameters: {'n_estimators': 1253, 'max_depth': 6, 'learning_rate': 4.7385523681562776e-05, 'subsample': 0.6, 'min_samples_split': 850}. Best is trial 1 with value: 0.7625201938610664.\u001b[0m\n",
      "\u001b[32m[I 2021-08-29 15:06:01,061]\u001b[0m Trial 5 finished with value: 0.7398843930635839 and parameters: {'n_estimators': 1465, 'max_depth': 5, 'learning_rate': 0.00013911845711284324, 'subsample': 0.5, 'min_samples_split': 780}. Best is trial 1 with value: 0.7625201938610664.\u001b[0m\n",
      "\u001b[32m[I 2021-08-29 15:18:27,681]\u001b[0m Trial 6 finished with value: 0.7699680511182109 and parameters: {'n_estimators': 4835, 'max_depth': 6, 'learning_rate': 0.006320036984820686, 'subsample': 1.0, 'min_samples_split': 230}. Best is trial 6 with value: 0.7699680511182109.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def gbm_objective(trial):\n",
    "    \n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 300, 5000)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-1, log=True)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0, step=0.1)\n",
    "    min_samples_split=trial.suggest_int(\"min_samples_split\", 100, 1000,step=10)\n",
    "    model = GradientBoostingClassifier(n_estimators=n_estimators,\n",
    "                         max_depth=max_depth,\n",
    "                         learning_rate=learning_rate,\n",
    "                         subsample=subsample, \n",
    "                        min_samples_split=min_samples_split,\n",
    "                         )  \n",
    "    return evaluate_model(model, X, y)\n",
    "\n",
    "study_gbm = optuna.create_study(study_name='gbm_optimze',direction='maximize')\n",
    "study_gbm.optimize(gbm_objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b07610",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study_gbm.best_trial)\n",
    "print(study_gbm.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f5a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_objective(trial):\n",
    "    \n",
    "    num_leaves = trial.suggest_int(\"num_leaves\", 24, 80)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-1, log=True)\n",
    "    feature_fraction=trial.suggest_float(\"feature_fraction\", 0.1, 0,9)\n",
    "    bagging_fraction=trial.suggest_float(\"bagging_fraction\", 0.8, 1)\n",
    "    max_depth=trial.suggest_int(\"max_depth\",5,30)\n",
    "    max_bin=trial.suggest_int(\"max_bin\",20,90)\n",
    "    max_data_in_leaf=trial.suggest_int(\"max_dat_in_leaf\",20,80)\n",
    "    min_sum_hessian_in_leaf=trial.suggest_int(\"min_sum_hessian_in_leaf\",0,100)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0, step=0.1)\n",
    "    model = LGBMClassifier(\n",
    "                        application='binary',\n",
    "                        eval_metric='auc',\n",
    "                        num_leaves=num_leaves,\n",
    "                        learning_rate=learning_rate,\n",
    "                        bagging_fraction=bagging_fraction,\n",
    "                        max_depth=max_depth,\n",
    "                        max_bin=max_bin,\n",
    "                        max_data_in_leaf=max_data_in_leaf,\n",
    "                        min_sum_hessian_in_leaf=min_sum_hessian_in_leaf,\n",
    "                        subsample=subsample,\n",
    "                        early_stopping_rounds = 250,\n",
    "                         tree_method='gpu_hist'\n",
    "                        n_jobs=-1, \n",
    "                        gpu_id=0)  \n",
    "    return evaluate_model(model, X, y)\n",
    "\n",
    "study_lgbm = optuna.create_study(study_name='lgbm_optimze',direction='maximize')\n",
    "study_lgbm.optimize(gbm_objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a872cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameters for the models from Optuna\n",
    "\n",
    "xgboost_parameters={'n_estimators': 843, 'max_depth': 7, 'learning_rate': 0.0034546899925579112, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.5}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
